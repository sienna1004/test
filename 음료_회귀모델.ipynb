{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "1nwd8rIMCBlB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df= pd.read_csv('회귀모델_전처리완료_v1.0.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuwtTmFpCfw4",
        "outputId": "8c8eba9a-5545-4417-c848-d6a68d1a515c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1161 entries, 0 to 1160\n",
            "Data columns (total 13 columns):\n",
            " #   Column                               Non-Null Count  Dtype  \n",
            "---  ------                               --------------  -----  \n",
            " 0   Unnamed: 0                           1161 non-null   int64  \n",
            " 1   브랜드                                  1161 non-null   object \n",
            " 2   유통 업체                                1161 non-null   object \n",
            " 3   카테고리                                 1161 non-null   object \n",
            " 4   포장 형태                                1161 non-null   object \n",
            " 5   최근 3년간 광고모델 및 IP 협업 여부 (2022~2024년)  1161 non-null   int64  \n",
            " 6   100ml당 가격                            1161 non-null   int64  \n",
            " 7   용량                                   1161 non-null   int64  \n",
            " 8   대체당                                  1161 non-null   object \n",
            " 9   음료명 기준 제로 여부                         1161 non-null   object \n",
            " 10  인기도                                  1161 non-null   float64\n",
            " 11  대체당 여부                               1161 non-null   int64  \n",
            " 12  대체당 조합                               1161 non-null   object \n",
            "dtypes: float64(1), int64(5), object(7)\n",
            "memory usage: 118.0+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "07Ql_MTSCitn"
      },
      "outputs": [],
      "source": [
        "# '대체당' 열 삭제\n",
        "df= df.drop(['Unnamed: 0','브랜드','대체당','대체당 여부'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "w0XO1licC3Q4",
        "outputId": "1a5f7984-148c-4ca2-fb3f-bcf7b6a4acd0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>유통 업체</th>\n",
              "      <th>카테고리</th>\n",
              "      <th>포장 형태</th>\n",
              "      <th>최근 3년간 광고모델 및 IP 협업 여부 (2022~2024년)</th>\n",
              "      <th>100ml당 가격</th>\n",
              "      <th>용량</th>\n",
              "      <th>음료명 기준 제로 여부</th>\n",
              "      <th>인기도</th>\n",
              "      <th>대체당 조합</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>페트</td>\n",
              "      <td>1</td>\n",
              "      <td>322</td>\n",
              "      <td>200</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>69.654006</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>페트</td>\n",
              "      <td>1</td>\n",
              "      <td>361</td>\n",
              "      <td>200</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>43.246780</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>유리병</td>\n",
              "      <td>0</td>\n",
              "      <td>528</td>\n",
              "      <td>150</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>73.306406</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>페트</td>\n",
              "      <td>0</td>\n",
              "      <td>273</td>\n",
              "      <td>500</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>40.011834</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>페트</td>\n",
              "      <td>0</td>\n",
              "      <td>296</td>\n",
              "      <td>500</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>58.161078</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1156</th>\n",
              "      <td>서울우유협동조합</td>\n",
              "      <td>과·채음료</td>\n",
              "      <td>페트</td>\n",
              "      <td>0</td>\n",
              "      <td>533</td>\n",
              "      <td>210</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>41.445982</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1157</th>\n",
              "      <td>서울우유협동조합</td>\n",
              "      <td>과·채음료</td>\n",
              "      <td>페트</td>\n",
              "      <td>0</td>\n",
              "      <td>510</td>\n",
              "      <td>210</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>62.688344</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1158</th>\n",
              "      <td>서울우유협동조합</td>\n",
              "      <td>유제품/대체유</td>\n",
              "      <td>팩</td>\n",
              "      <td>0</td>\n",
              "      <td>354</td>\n",
              "      <td>190</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>55.055714</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1159</th>\n",
              "      <td>서울우유협동조합</td>\n",
              "      <td>유제품/대체유</td>\n",
              "      <td>파우치</td>\n",
              "      <td>0</td>\n",
              "      <td>217</td>\n",
              "      <td>190</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>46.012262</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1160</th>\n",
              "      <td>서울우유협동조합</td>\n",
              "      <td>유제품/대체유</td>\n",
              "      <td>팩</td>\n",
              "      <td>0</td>\n",
              "      <td>567</td>\n",
              "      <td>190</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>16.323792</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1161 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         유통 업체     카테고리 포장 형태  최근 3년간 광고모델 및 IP 협업 여부 (2022~2024년)  100ml당 가격  \\\n",
              "0         광동제약        차    페트                                    1        322   \n",
              "1         광동제약        차    페트                                    1        361   \n",
              "2         광동제약        차   유리병                                    0        528   \n",
              "3         광동제약        차    페트                                    0        273   \n",
              "4         광동제약        차    페트                                    0        296   \n",
              "...        ...      ...   ...                                  ...        ...   \n",
              "1156  서울우유협동조합    과·채음료    페트                                    0        533   \n",
              "1157  서울우유협동조합    과·채음료    페트                                    0        510   \n",
              "1158  서울우유협동조합  유제품/대체유     팩                                    0        354   \n",
              "1159  서울우유협동조합  유제품/대체유   파우치                                    0        217   \n",
              "1160  서울우유협동조합  유제품/대체유     팩                                    0        567   \n",
              "\n",
              "       용량 음료명 기준 제로 여부        인기도  대체당 조합  \n",
              "0     200        일반 음료  69.654006  대체당 없음  \n",
              "1     200        일반 음료  43.246780  대체당 없음  \n",
              "2     150        일반 음료  73.306406  대체당 없음  \n",
              "3     500        일반 음료  40.011834  대체당 없음  \n",
              "4     500        일반 음료  58.161078  대체당 없음  \n",
              "...   ...          ...        ...     ...  \n",
              "1156  210        일반 음료  41.445982  대체당 없음  \n",
              "1157  210        일반 음료  62.688344  대체당 없음  \n",
              "1158  190        일반 음료  55.055714  대체당 없음  \n",
              "1159  190        일반 음료  46.012262  대체당 없음  \n",
              "1160  190        일반 음료  16.323792  대체당 없음  \n",
              "\n",
              "[1161 rows x 9 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tD5A1ZojDAHv"
      },
      "source": [
        "- 컬럼명 변경: 편의를 위해 컬럼명을 변경합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "pGl1BVdBC8Kn"
      },
      "outputs": [],
      "source": [
        "column_mapper = {\n",
        "    '유통 업체': 'distributor',\n",
        "    '카테고리': 'category',\n",
        "    '포장 형태': 'packaging',\n",
        "    '최근 3년간 광고모델 및 IP 협업 여부 (2022~2024년)': 'ad_collab',\n",
        "    '100ml당 가격': 'price_100ml',\n",
        "    '용량': 'volume',\n",
        "    '음료명 기준 제로 여부': 'zero_type',\n",
        "    '인기도': 'popularity',\n",
        "    '대체당 조합': 'sweetener_mix'\n",
        "}\n",
        "\n",
        "df = df.rename(columns=column_mapper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "kpSNjZp9D07f",
        "outputId": "31e8f976-d3a3-4bf6-ecb5-9c5df550a8da"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>distributor</th>\n",
              "      <th>category</th>\n",
              "      <th>packaging</th>\n",
              "      <th>zero_type</th>\n",
              "      <th>sweetener_mix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1161</td>\n",
              "      <td>1161</td>\n",
              "      <td>1161</td>\n",
              "      <td>1161</td>\n",
              "      <td>1161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>18</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>롯데칠성음료</td>\n",
              "      <td>탄산음료</td>\n",
              "      <td>페트</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>173</td>\n",
              "      <td>250</td>\n",
              "      <td>522</td>\n",
              "      <td>956</td>\n",
              "      <td>695</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       distributor category packaging zero_type sweetener_mix\n",
              "count         1161     1161      1161      1161          1161\n",
              "unique          18        8         7         2             4\n",
              "top         롯데칠성음료     탄산음료        페트     일반 음료        대체당 없음\n",
              "freq           173      250       522       956           695"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe(include='object')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "vEjoMaAnET_v",
        "outputId": "f2eb761b-821e-47cf-b0e8-0cc6d561c796"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ad_collab</th>\n",
              "      <th>price_100ml</th>\n",
              "      <th>volume</th>\n",
              "      <th>popularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1161.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.403962</td>\n",
              "      <td>312.901809</td>\n",
              "      <td>443.474591</td>\n",
              "      <td>46.504633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.490902</td>\n",
              "      <td>195.924833</td>\n",
              "      <td>392.140584</td>\n",
              "      <td>23.553922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>30.861535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>300.000000</td>\n",
              "      <td>46.263781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>398.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>62.208756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1793.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ad_collab  price_100ml       volume   popularity\n",
              "count  1161.000000  1161.000000  1161.000000  1161.000000\n",
              "mean      0.403962   312.901809   443.474591    46.504633\n",
              "std       0.490902   195.924833   392.140584    23.553922\n",
              "min       0.000000    53.000000    75.000000     0.000000\n",
              "25%       0.000000   174.000000   200.000000    30.861535\n",
              "50%       0.000000   253.000000   300.000000    46.263781\n",
              "75%       1.000000   398.000000   500.000000    62.208756\n",
              "max       1.000000  1793.000000  3000.000000   100.000000"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "sweetener_mix\n",
              "대체당 없음       695\n",
              "합성 대체당       189\n",
              "천연+합성 대체당    161\n",
              "천연 대체당       116\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['sweetener_mix'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lstlffuUEmTP"
      },
      "source": [
        "CatBoost는 자체적으로 범주형 변수를 처리하므로 별도의 인코딩이 필요 없습니다.\n",
        "연속형 변수는 별도의 스케일링 없이 원본 그대로 사용 가능합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYFNOsdxFCnW",
        "outputId": "97c86e7c-08c0-43dc-806f-d78ef8775e1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.2.7)\n",
            "Requirement already satisfied: graphviz in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: scipy in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (1.15.2)\n",
            "Requirement already satisfied: six in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: plotly in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (6.0.0)\n",
            "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: pandas>=0.24 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from catboost) (2.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (3.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->catboost) (4.56.0)\n",
            "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from plotly->catboost) (1.27.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
            "You should consider upgrading via the 'C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAgGwP0wU8tO"
      },
      "source": [
        "## 데이터 요약\n",
        "- 독립\n",
        "    - 범주: 유통업체(16), 카테고리(8), 포장형태(7), IP 협업 (2), 음료명 기준 제로 여부(3), 대체당 조합(4)\n",
        "    - 연속: 100ml당 가격, 용량\n",
        "- 종속\n",
        "    - 인기도\n",
        "\n",
        "## 모델 선택\n",
        "- 현재 데이터는 범주형 변수가 연속형 변수보다 많다. 따라서 범주형 변수 처리가 용이한 알고리즘이 적절하다.\n",
        "\n",
        "## 모델 후보\n",
        "- Catboost\n",
        "- Random Forest\n",
        "- LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLbHPkD4E-qV",
        "outputId": "b90ef87d-ef6e-4310-9846-139177620282"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tlearn: 23.2003384\ttest: 22.4758750\tbest: 22.4758750 (0)\ttotal: 154ms\tremaining: 2m 33s\n",
            "200:\tlearn: 14.1958843\ttest: 18.5424188\tbest: 18.5424188 (200)\ttotal: 2.37s\tremaining: 9.42s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 18.51625796\n",
            "bestIteration = 202\n",
            "\n",
            "Shrink model to first 203 iterations.\n",
            "\n",
            "=== 모델 성능 평가 ===\n",
            "\n",
            "훈련 세트 성능:\n",
            "RMSE: 15.8976\n",
            "R2 Score: 0.5500\n",
            "\n",
            "테스트 세트 성능:\n",
            "RMSE: 18.5163\n",
            "R2 Score: 0.3461\n",
            "\n",
            "=== 특성 중요도 ===\n",
            "         feature  importance\n",
            "0    distributor   35.448179\n",
            "1       category   19.610642\n",
            "6    price_100ml   11.822751\n",
            "4  sweetener_mix    9.974611\n",
            "2      packaging    9.486537\n",
            "7         volume    6.045326\n",
            "5      ad_collab    5.809024\n",
            "3      zero_type    1.802930\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# 1. 필요한 컬럼 선택\n",
        "feature_columns = [\n",
        "   'distributor', 'category', 'packaging', 'zero_type', 'sweetener_mix',  # 범주형\n",
        "   'ad_collab', 'price_100ml', 'volume'  # 연속형\n",
        "]\n",
        "target_column = 'popularity'\n",
        "\n",
        "X = df[feature_columns]\n",
        "y = df[target_column]\n",
        "\n",
        "# 2. 범주형 변수 리스트 생성\n",
        "categorical_features = [\n",
        "   'distributor',\n",
        "   'category',\n",
        "   'packaging',\n",
        "   'zero_type',\n",
        "   'sweetener_mix'\n",
        "]\n",
        "\n",
        "\n",
        "# 4. 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "   X, y,\n",
        "   test_size=0.2,\n",
        "   random_state=42\n",
        ")\n",
        "\n",
        "# 5. CatBoost 모델 정의\n",
        "cat_model = CatBoostRegressor(\n",
        "   iterations=1000,\n",
        "   learning_rate=0.1,\n",
        "   depth=6,\n",
        "   cat_features=categorical_features,\n",
        "   eval_metric='RMSE',\n",
        "   random_seed=42,\n",
        "   verbose=200\n",
        ")\n",
        "\n",
        "# 6. 모델 학습\n",
        "cat_model.fit(\n",
        "   X_train, y_train,\n",
        "   eval_set=(X_test, y_test),\n",
        "   early_stopping_rounds=100,\n",
        "   verbose=200\n",
        ")\n",
        "\n",
        "# 7. 예측 및 평가지표 계산\n",
        "y_pred_train = cat_model.predict(X_train)\n",
        "y_pred_test = cat_model.predict(X_test)\n",
        "\n",
        "# 훈련 세트 평가\n",
        "train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "train_r2 = r2_score(y_train, y_pred_train)\n",
        "\n",
        "# 테스트 세트 평가\n",
        "test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "test_r2 = r2_score(y_test, y_pred_test)\n",
        "\n",
        "print(\"\\n=== 모델 성능 평가 ===\")\n",
        "print(\"\\n훈련 세트 성능:\")\n",
        "print(f\"RMSE: {train_rmse:.4f}\")\n",
        "print(f\"R2 Score: {train_r2:.4f}\")\n",
        "\n",
        "print(\"\\n테스트 세트 성능:\")\n",
        "print(f\"RMSE: {test_rmse:.4f}\")\n",
        "print(f\"R2 Score: {test_r2:.4f}\")\n",
        "\n",
        "# 8. 특성 중요도 확인\n",
        "feature_importance = pd.DataFrame({\n",
        "   'feature': feature_columns,\n",
        "   'importance': cat_model.feature_importances_\n",
        "})\n",
        "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
        "print(\"\\n=== 특성 중요도 ===\")\n",
        "print(feature_importance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "LNKd3Qn0FuUQ",
        "outputId": "4a902979-a01b-404b-f1cb-1e041d47e620"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count    1161.000000\n",
              "mean       46.504633\n",
              "std        23.553922\n",
              "min         0.000000\n",
              "25%        30.861535\n",
              "50%        46.263781\n",
              "75%        62.208756\n",
              "max       100.000000\n",
              "Name: popularity, dtype: float64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['popularity'].describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkK9Xc7GGy-X"
      },
      "source": [
        "이는 100점 만점의 시험에서 평균적으로 18.5점 정도 틀릴 수 있다고 볼 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fL57BHgMHKr_"
      },
      "outputs": [],
      "source": [
        "from category_encoders import TargetEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctd62MweHORG",
        "outputId": "59231118-e515-4c78-e4f7-d2cdeda4c30c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.8.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (1.13.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from category_encoders) (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.5->category_encoders) (2025.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.6.0->category_encoders) (3.5.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.5->category_encoders) (1.17.0)\n",
            "Downloading category_encoders-2.8.0-py3-none-any.whl (85 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install category_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "I64yemEbHXEy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from category_encoders import TargetEncoder\n",
        "\n",
        "# 1. 데이터 준비\n",
        "feature_columns = [\n",
        "    'distributor', 'category', 'packaging', 'zero_type', 'sweetener_mix',  # 범주형\n",
        "    'ad_collab', 'price_100ml', 'volume'  # 연속형\n",
        "]\n",
        "categorical_features = [\n",
        "    'distributor', 'category', 'packaging', 'zero_type', 'sweetener_mix'\n",
        "]\n",
        "target_column = 'popularity'\n",
        "\n",
        "X = df[feature_columns]\n",
        "y = df[target_column]\n",
        "\n",
        "# 2. 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Target Encoding\n",
        "te = TargetEncoder()\n",
        "X_train_rf = X_train.copy()\n",
        "X_test_rf = X_test.copy()\n",
        "X_train_rf[categorical_features] = te.fit_transform(X_train[categorical_features], y_train)\n",
        "X_test_rf[categorical_features] = te.transform(X_test[categorical_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jrFE7tFrHX_u",
        "outputId": "d24b21f7-350c-4188-87c3-bbf597e03012"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>distributor</th>\n",
              "      <th>category</th>\n",
              "      <th>packaging</th>\n",
              "      <th>zero_type</th>\n",
              "      <th>sweetener_mix</th>\n",
              "      <th>ad_collab</th>\n",
              "      <th>price_100ml</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>759</th>\n",
              "      <td>44.911086</td>\n",
              "      <td>40.361693</td>\n",
              "      <td>43.882723</td>\n",
              "      <td>52.353464</td>\n",
              "      <td>45.419530</td>\n",
              "      <td>0</td>\n",
              "      <td>187</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>816</th>\n",
              "      <td>44.911086</td>\n",
              "      <td>44.178008</td>\n",
              "      <td>43.882723</td>\n",
              "      <td>45.516546</td>\n",
              "      <td>46.464956</td>\n",
              "      <td>1</td>\n",
              "      <td>98</td>\n",
              "      <td>1000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>862</th>\n",
              "      <td>52.193048</td>\n",
              "      <td>55.236580</td>\n",
              "      <td>52.753494</td>\n",
              "      <td>45.516546</td>\n",
              "      <td>48.158371</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>52.112058</td>\n",
              "      <td>44.178008</td>\n",
              "      <td>43.882723</td>\n",
              "      <td>45.516546</td>\n",
              "      <td>46.464956</td>\n",
              "      <td>0</td>\n",
              "      <td>164</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>693</th>\n",
              "      <td>44.911086</td>\n",
              "      <td>40.361693</td>\n",
              "      <td>43.882723</td>\n",
              "      <td>45.516546</td>\n",
              "      <td>46.464956</td>\n",
              "      <td>0</td>\n",
              "      <td>177</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1044</th>\n",
              "      <td>40.032194</td>\n",
              "      <td>42.353763</td>\n",
              "      <td>43.882723</td>\n",
              "      <td>45.516546</td>\n",
              "      <td>47.663541</td>\n",
              "      <td>1</td>\n",
              "      <td>298</td>\n",
              "      <td>235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1095</th>\n",
              "      <td>40.114500</td>\n",
              "      <td>40.361693</td>\n",
              "      <td>43.882723</td>\n",
              "      <td>45.516546</td>\n",
              "      <td>46.464956</td>\n",
              "      <td>0</td>\n",
              "      <td>318</td>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>43.934227</td>\n",
              "      <td>42.353763</td>\n",
              "      <td>43.882723</td>\n",
              "      <td>45.516546</td>\n",
              "      <td>48.158371</td>\n",
              "      <td>0</td>\n",
              "      <td>270</td>\n",
              "      <td>500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>52.193048</td>\n",
              "      <td>55.236580</td>\n",
              "      <td>52.753494</td>\n",
              "      <td>52.353464</td>\n",
              "      <td>48.158371</td>\n",
              "      <td>0</td>\n",
              "      <td>328</td>\n",
              "      <td>250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1126</th>\n",
              "      <td>43.934227</td>\n",
              "      <td>40.361693</td>\n",
              "      <td>41.879213</td>\n",
              "      <td>45.516546</td>\n",
              "      <td>46.464956</td>\n",
              "      <td>0</td>\n",
              "      <td>229</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>928 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      distributor   category  packaging  zero_type  sweetener_mix  ad_collab  \\\n",
              "759     44.911086  40.361693  43.882723  52.353464      45.419530          0   \n",
              "816     44.911086  44.178008  43.882723  45.516546      46.464956          1   \n",
              "862     52.193048  55.236580  52.753494  45.516546      48.158371          0   \n",
              "394     52.112058  44.178008  43.882723  45.516546      46.464956          0   \n",
              "693     44.911086  40.361693  43.882723  45.516546      46.464956          0   \n",
              "...           ...        ...        ...        ...            ...        ...   \n",
              "1044    40.032194  42.353763  43.882723  45.516546      47.663541          1   \n",
              "1095    40.114500  40.361693  43.882723  45.516546      46.464956          0   \n",
              "1130    43.934227  42.353763  43.882723  45.516546      48.158371          0   \n",
              "860     52.193048  55.236580  52.753494  52.353464      48.158371          0   \n",
              "1126    43.934227  40.361693  41.879213  45.516546      46.464956          0   \n",
              "\n",
              "      price_100ml  volume  \n",
              "759           187     500  \n",
              "816            98    1000  \n",
              "862           255     190  \n",
              "394           164     500  \n",
              "693           177     500  \n",
              "...           ...     ...  \n",
              "1044          298     235  \n",
              "1095          318     300  \n",
              "1130          270     500  \n",
              "860           328     250  \n",
              "1126          229     200  \n",
              "\n",
              "[928 rows x 8 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_rf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LAmXkZnGzz6",
        "outputId": "248b3ca5-af03-4bda-ac71-e8352a24ed59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Random Forest ===\n",
            "\n",
            "Random Forest 성능:\n",
            "훈련 세트 성능:\n",
            "RMSE: 15.9076\n",
            "R2 Score: 0.5494\n",
            "\n",
            "테스트 세트 성능:\n",
            "RMSE: 18.5474\n",
            "R2 Score: 0.3439\n"
          ]
        }
      ],
      "source": [
        "# 3. Random Forest\n",
        "print(\"\\n=== Random Forest ===\")\n",
        "\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train_rf, y_train)\n",
        "\n",
        "# RF 성능 평가\n",
        "rf_pred_train = rf_model.predict(X_train_rf)\n",
        "rf_pred_test = rf_model.predict(X_test_rf)\n",
        "\n",
        "print(\"\\nRandom Forest 성능:\")\n",
        "print(\"훈련 세트 성능:\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_train, rf_pred_train)):.4f}\")\n",
        "print(f\"R2 Score: {r2_score(y_train, rf_pred_train):.4f}\")\n",
        "print(\"\\n테스트 세트 성능:\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, rf_pred_test)):.4f}\")\n",
        "print(f\"R2 Score: {r2_score(y_test, rf_pred_test):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoBfJn5HIZZe",
        "outputId": "134dacde-438c-4ee2-be90-28216ffe4fcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Random Forest ===\n",
            "\n",
            "Random Forest 성능:\n",
            "훈련 세트 성능:\n",
            "RMSE: 15.9076\n",
            "R2 Score: 0.5494\n",
            "\n",
            "테스트 세트 성능:\n",
            "RMSE: 18.5474\n",
            "R2 Score: 0.3439\n",
            "\n",
            "=== LightGBM ===\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000154 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 344\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 46.710061\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "LightGBM 성능:\n",
            "훈련 세트 성능:\n",
            "RMSE: 12.1912\n",
            "R2 Score: 0.7354\n",
            "\n",
            "테스트 세트 성능:\n",
            "RMSE: 18.2220\n",
            "R2 Score: 0.3668\n",
            "\n",
            "=== Random Forest 특성 중요도 ===\n",
            "         feature  importance\n",
            "0    distributor    0.403999\n",
            "1       category    0.183861\n",
            "6    price_100ml    0.183000\n",
            "7         volume    0.086003\n",
            "5      ad_collab    0.054296\n",
            "2      packaging    0.044812\n",
            "4  sweetener_mix    0.029131\n",
            "3      zero_type    0.014898\n",
            "\n",
            "=== LightGBM 특성 중요도 ===\n",
            "         feature  importance\n",
            "6    price_100ml        1088\n",
            "7         volume         521\n",
            "0    distributor         175\n",
            "5      ad_collab         118\n",
            "1       category          98\n",
            "3      zero_type          74\n",
            "4  sweetener_mix          43\n",
            "2      packaging          29\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from category_encoders import TargetEncoder\n",
        "\n",
        "# 1. 데이터 준비\n",
        "feature_columns = [\n",
        "    'distributor', 'category', 'packaging', 'zero_type', 'sweetener_mix',  # 범주형\n",
        "    'ad_collab', 'price_100ml', 'volume'  # 연속형\n",
        "]\n",
        "categorical_features = [\n",
        "    'distributor', 'category', 'packaging', 'zero_type', 'sweetener_mix'\n",
        "]\n",
        "target_column = 'popularity'\n",
        "\n",
        "X = df[feature_columns]\n",
        "y = df[target_column]\n",
        "\n",
        "# 2. 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Random Forest\n",
        "print(\"\\n=== Random Forest ===\")\n",
        "\n",
        "# Target Encoding\n",
        "te = TargetEncoder()\n",
        "X_train_rf = X_train.copy()\n",
        "X_test_rf = X_test.copy()\n",
        "X_train_rf[categorical_features] = te.fit_transform(X_train[categorical_features], y_train)\n",
        "X_test_rf[categorical_features] = te.transform(X_test[categorical_features])\n",
        "\n",
        "rf_model = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_model.fit(X_train_rf, y_train)\n",
        "\n",
        "# RF 성능 평가\n",
        "rf_pred_train = rf_model.predict(X_train_rf)\n",
        "rf_pred_test = rf_model.predict(X_test_rf)\n",
        "\n",
        "print(\"\\nRandom Forest 성능:\")\n",
        "print(\"훈련 세트 성능:\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_train, rf_pred_train)):.4f}\")\n",
        "print(f\"R2 Score: {r2_score(y_train, rf_pred_train):.4f}\")\n",
        "print(\"\\n테스트 세트 성능:\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, rf_pred_test)):.4f}\")\n",
        "print(f\"R2 Score: {r2_score(y_test, rf_pred_test):.4f}\")\n",
        "\n",
        "# 4. LightGBM\n",
        "print(\"\\n=== LightGBM ===\")\n",
        "\n",
        "# Label Encoding for LightGBM\n",
        "X_train_lgb = X_train.copy()\n",
        "X_test_lgb = X_test.copy()\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le_dict = {}\n",
        "for col in categorical_features:\n",
        "    le_dict[col] = LabelEncoder()\n",
        "    X_train_lgb[col] = le_dict[col].fit_transform(X_train_lgb[col])\n",
        "    X_test_lgb[col] = le_dict[col].transform(X_test_lgb[col])\n",
        "\n",
        "# LightGBM 모델 정의 - categorical_feature 수정\n",
        "categorical_indices = [X_train_lgb.columns.get_loc(col) for col in categorical_features]\n",
        "\n",
        "lgb_model = LGBMRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# categorical_feature를 fit 메서드에서 지정\n",
        "lgb_model.fit(\n",
        "    X_train_lgb,\n",
        "    y_train,\n",
        "    categorical_feature=categorical_indices\n",
        ")\n",
        "\n",
        "# LightGBM 성능 평가\n",
        "lgb_pred_train = lgb_model.predict(X_train_lgb)\n",
        "lgb_pred_test = lgb_model.predict(X_test_lgb)\n",
        "\n",
        "print(\"\\nLightGBM 성능:\")\n",
        "print(\"훈련 세트 성능:\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_train, lgb_pred_train)):.4f}\")\n",
        "print(f\"R2 Score: {r2_score(y_train, lgb_pred_train):.4f}\")\n",
        "print(\"\\n테스트 세트 성능:\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, lgb_pred_test)):.4f}\")\n",
        "print(f\"R2 Score: {r2_score(y_test, lgb_pred_test):.4f}\")\n",
        "\n",
        "# 5. 특성 중요도 비교\n",
        "# Random Forest 특성 중요도\n",
        "rf_importance = pd.DataFrame({\n",
        "    'feature': feature_columns,\n",
        "    'importance': rf_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "# LightGBM 특성 중요도\n",
        "lgb_importance = pd.DataFrame({\n",
        "    'feature': feature_columns,\n",
        "    'importance': lgb_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\n=== Random Forest 특성 중요도 ===\")\n",
        "print(rf_importance)\n",
        "print(\"\\n=== LightGBM 특성 중요도 ===\")\n",
        "print(lgb_importance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF2W1BhjTT2-"
      },
      "source": [
        "|| CatBoost | random forest | LightGBM |\n",
        "|-|-|-|-|\n",
        "|RMSE|18.5163 | 18.5474 | 18.2220|\n",
        "|R2 Score| 0.3461 | 0.3439 | 0.3668|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neezpMKaeKne"
      },
      "source": [
        "- 세 모델중 LightGBM의 예측 오차평균이 가장 낮고 데이터 설명력이 높으므로 해당 알고리즘으로 심층적인 테스트 진행.\n",
        "- 다음으로 LightGBM모델의 하이퍼파라미터 튜닝 진행."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHM37JDmTZiv",
        "outputId": "bc53e8fe-aa4f-4c9c-ca31-a332909f88b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 341\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 46.710061\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "최적 파라미터:\n",
            "{'learning_rate': 0.05, 'max_depth': 6, 'n_estimators': 300, 'num_leaves': 31}\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 344\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 46.710061\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "\n",
            "최적 모델 성능:\n",
            "훈련 세트 성능:\n",
            "RMSE: 11.5126\n",
            "R2 Score: 0.7640\n",
            "\n",
            "테스트 세트 성능:\n",
            "RMSE: 18.2689\n",
            "R2 Score: 0.3635\n",
            "\n",
            "=== 특성 중요도 ===\n",
            "         feature  importance\n",
            "6    price_100ml        2777\n",
            "7         volume        1617\n",
            "0    distributor         456\n",
            "5      ad_collab         408\n",
            "1       category         276\n",
            "3      zero_type         234\n",
            "4  sweetener_mix         117\n",
            "2      packaging         101\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 1. 데이터 준비\n",
        "feature_columns = [\n",
        "   'distributor', 'category', 'packaging', 'zero_type', 'sweetener_mix',  # 범주형\n",
        "   'ad_collab', 'price_100ml', 'volume'  # 연속형\n",
        "]\n",
        "categorical_features = [\n",
        "   'distributor', 'category', 'packaging', 'zero_type', 'sweetener_mix'\n",
        "]\n",
        "target_column = 'popularity'\n",
        "\n",
        "X = df[feature_columns]\n",
        "y = df[target_column]\n",
        "\n",
        "# 2. 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "   X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Label Encoding\n",
        "X_train_lgb = X_train.copy()\n",
        "X_test_lgb = X_test.copy()\n",
        "\n",
        "le_dict = {}\n",
        "for col in categorical_features:\n",
        "   le_dict[col] = LabelEncoder()\n",
        "   X_train_lgb[col] = le_dict[col].fit_transform(X_train_lgb[col])\n",
        "   X_test_lgb[col] = le_dict[col].transform(X_test_lgb[col])\n",
        "\n",
        "# categorical_feature를 컬럼 인덱스로 변경\n",
        "categorical_indices = [X_train_lgb.columns.get_loc(col) for col in categorical_features]\n",
        "\n",
        "# 4. 그리드 서치를 위한 파라미터 정의\n",
        "param_grid = {\n",
        "   'n_estimators': [100, 200, 300],\n",
        "   'max_depth': [4, 6, 8],\n",
        "   'learning_rate': [0.01, 0.05, 0.1],\n",
        "   'num_leaves': [15, 31, 63],\n",
        "}\n",
        "\n",
        "# 5. 기본 모델 정의\n",
        "base_model = LGBMRegressor(\n",
        "   random_state=42,\n",
        "   subsample=0.8,\n",
        "   colsample_bytree=0.8,\n",
        "   min_child_samples=20\n",
        ")\n",
        "\n",
        "# 6. GridSearchCV 수행\n",
        "grid_search = GridSearchCV(\n",
        "   estimator=base_model,\n",
        "   param_grid=param_grid,\n",
        "   cv=5,\n",
        "   scoring='neg_root_mean_squared_error',\n",
        "   n_jobs=-1,\n",
        "   verbose=2\n",
        ")\n",
        "\n",
        "# categorical_feature를 fit 메서드에서 지정\n",
        "grid_search.fit(X_train_lgb, y_train)\n",
        "\n",
        "# 7. 최적 파라미터 출력\n",
        "print(\"\\n최적 파라미터:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# 8. 최적 파라미터로 새로운 모델 학습\n",
        "best_params = grid_search.best_params_\n",
        "best_model = LGBMRegressor(\n",
        "   **best_params,\n",
        "   random_state=42,\n",
        "   subsample=0.8,\n",
        "   colsample_bytree=0.8,\n",
        "   min_child_samples=20\n",
        ")\n",
        "\n",
        "best_model.fit(\n",
        "   X_train_lgb,\n",
        "   y_train,\n",
        "   categorical_feature=categorical_indices\n",
        ")\n",
        "\n",
        "# 9. 성능 평가\n",
        "train_pred = best_model.predict(X_train_lgb)\n",
        "test_pred = best_model.predict(X_test_lgb)\n",
        "\n",
        "print(\"\\n최적 모델 성능:\")\n",
        "print(\"훈련 세트 성능:\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_train, train_pred)):.4f}\")\n",
        "print(f\"R2 Score: {r2_score(y_train, train_pred):.4f}\")\n",
        "print(\"\\n테스트 세트 성능:\")\n",
        "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, test_pred)):.4f}\")\n",
        "print(f\"R2 Score: {r2_score(y_test, test_pred):.4f}\")\n",
        "\n",
        "# 10. 특성 중요도\n",
        "feature_importance = pd.DataFrame({\n",
        "   'feature': feature_columns,\n",
        "   'importance': best_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\n=== 특성 중요도 ===\")\n",
        "print(feature_importance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2u-J-JMepvt"
      },
      "source": [
        "- 파라미터 튜닝결과 성능향상이 보이지 않는다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ssZR8FCbf_F"
      },
      "source": [
        "- 학습 데이터에 대한 예측은 잘 이루어지나 테스트데이터에 대한 낮은 예측률로 보아 모델이 과적합을 일으킬 가능성이 존재한다.\n",
        "- 과적합을 줄일 수 있는 LightGBM의 bagging모델 사용."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbdyw4dRXb7W",
        "outputId": "7a0895a5-8afa-4eab-c2ba-4c50e54c36ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 380\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 48.511652\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 373\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 47.052490\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 372\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 46.150921\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 375\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 47.178196\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000115 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 375\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 45.558637\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 371\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 47.173860\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 369\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 46.541520\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 374\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 46.292738\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 373\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 46.232504\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 369\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 46.761537\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 373\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 47.682420\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 375\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 47.157592\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 378\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 46.369707\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 373\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 46.408590\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000105 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 369\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.981646\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000172 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 367\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 47.096547\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 375\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 46.121710\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 371\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.162202\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 373\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 46.559248\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 373\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 45.227351\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000077 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 373\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 48.032642\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000075 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 373\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.157715\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 375\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 47.978330\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000067 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 367\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.572944\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 370\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 45.361523\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 378\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 48.227327\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 374\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 47.626808\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000202 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 371\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 48.449794\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000106 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 374\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 46.751725\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 370\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 45.194808\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 375\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 48.519113\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000054 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 376\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 47.398053\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 372\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 46.621761\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000074 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 373\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.876469\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 373\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 46.620133\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000078 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 370\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 47.189606\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000077 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 374\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 46.624766\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000077 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 370\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.538400\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000096 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 364\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.144499\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 372\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.620638\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000085 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 370\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 47.639125\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000180 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 371\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 45.965726\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 368\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 47.515727\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 372\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 47.150817\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000076 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 374\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.633871\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 373\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 46.593551\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000077 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 375\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 45.312555\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000078 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 372\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.818842\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000046 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 369\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 47.058062\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000072 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 372\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 40\n",
            "[LightGBM] [Info] Start training from score 47.289653\n",
            "훈련 세트 RMSE: 12.3920\n",
            "훈련 세트 R2: 0.7266\n",
            "테스트 세트 RMSE: 18.0728\n",
            "테스트 세트 R2: 0.3771\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import lightgbm as lgb\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "\n",
        "# 데이터 로드 및 전처리 (예시)\n",
        "# df는 주어진 데이터프레임을 가정합니다.\n",
        "\n",
        "# 1. 범주형 변수 One-Hot Encoding 및 연속형 변수 스케일링\n",
        "X = df.drop(columns=['popularity'])  # 'popularity'를 종속 변수로 설정\n",
        "y = df['popularity']  # 타겟 변수는 'popularity'\n",
        "\n",
        "# 범주형 변수 및 연속형 변수 목록\n",
        "categorical_features = ['distributor', 'category', 'packaging', 'zero_type', 'sweetener_mix']\n",
        "numerical_features = ['ad_collab', 'price_100ml', 'volume']\n",
        "\n",
        "# 전처리 파이프라인 구성\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),  # 연속형 변수 정규화\n",
        "        ('cat', OneHotEncoder(), categorical_features)  # 범주형 변수 원-핫 인코딩\n",
        "    ])\n",
        "\n",
        "# 2. LightGBM 모델을 Wrapping한 클래스를 base_estimator로 사용\n",
        "class LGBMWrapper(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, **params):\n",
        "        self.model = lgb.LGBMRegressor(**params)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "# 3. BaggingRegressor에 LightGBM 모델을 사용\n",
        "model = LGBMWrapper(num_leaves=31, max_depth=7, learning_rate=0.05)\n",
        "\n",
        "# BaggingRegressor에 base_estimator로 사용\n",
        "bagging_model = BaggingRegressor(estimator=model, n_estimators=50, random_state=42)\n",
        "\n",
        "# 4. 파이프라인 구성\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('bagging', bagging_model)\n",
        "])\n",
        "\n",
        "# 5. 훈련 및 테스트 데이터 분할\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. 모델 훈련\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# 7. 예측\n",
        "y_pred_train = pipeline.predict(X_train)\n",
        "y_pred_test = pipeline.predict(X_test)\n",
        "\n",
        "# 8. 성능 평가\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "r2_train = r2_score(y_train, y_pred_train)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "r2_test = r2_score(y_test, y_pred_test)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"훈련 세트 RMSE: {rmse_train:.4f}\")\n",
        "print(f\"훈련 세트 R2: {r2_train:.4f}\")\n",
        "print(f\"테스트 세트 RMSE: {rmse_test:.4f}\")\n",
        "print(f\"테스트 세트 R2: {r2_test:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C9EyAqtewPV"
      },
      "source": [
        "- 미약한 성능향상이 보인다.\n",
        "\n",
        "|| LightGBM | LightGBM bagging |\n",
        "|-|-|-|\n",
        "|RMSE|18.2220 | 18.5474 |\n",
        "|R2 Score| 0.3668 |  0.3771 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqekxdubfOG9"
      },
      "source": [
        "- 특정 변수의 문제(예. 과도한 편향성, 또는 이상치)의 문제 일 수 있으므로 변수 분포 재확인.\n",
        "- LightGBM모델의 변수 중요도 확인.\n",
        "\n",
        "\n",
        "||feature | importance|\n",
        "|-|-|-|\n",
        "|1위| price_100ml  |     2777|\n",
        "|2위|  volume     |   1617|\n",
        "|3위|   distributor    |     456|\n",
        "\n",
        "\n",
        "100ml당 가격과 용량의 중요도가 타 변수보다 과도하게 높은점에 착안하여 일부 변수를 제거하고 과적합을 방지시도."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "d0VTykOFZElm",
        "outputId": "07a6635e-7aff-4287-ef5d-2668bb8ded46"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ad_collab</th>\n",
              "      <th>price_100ml</th>\n",
              "      <th>volume</th>\n",
              "      <th>popularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1161.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "      <td>1161.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.403962</td>\n",
              "      <td>312.901809</td>\n",
              "      <td>443.474591</td>\n",
              "      <td>46.504633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.490902</td>\n",
              "      <td>195.924833</td>\n",
              "      <td>392.140584</td>\n",
              "      <td>23.553922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>174.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>30.861535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>253.000000</td>\n",
              "      <td>300.000000</td>\n",
              "      <td>46.263781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>398.000000</td>\n",
              "      <td>500.000000</td>\n",
              "      <td>62.208756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1793.000000</td>\n",
              "      <td>3000.000000</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ad_collab  price_100ml       volume   popularity\n",
              "count  1161.000000  1161.000000  1161.000000  1161.000000\n",
              "mean      0.403962   312.901809   443.474591    46.504633\n",
              "std       0.490902   195.924833   392.140584    23.553922\n",
              "min       0.000000    53.000000    75.000000     0.000000\n",
              "25%       0.000000   174.000000   200.000000    30.861535\n",
              "50%       0.000000   253.000000   300.000000    46.263781\n",
              "75%       1.000000   398.000000   500.000000    62.208756\n",
              "max       1.000000  1793.000000  3000.000000   100.000000"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MGKKbBzZZ1G",
        "outputId": "c0d75cf4-5a47-4e9c-e380-38c13d46e018"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 331\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 48.511652\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000061 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 47.052490\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.150921\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 328\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 47.178196\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000164 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 330\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 45.558637\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 47.173860\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000069 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 46.541520\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 330\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.292738\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000082 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 328\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.232504\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000101 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 326\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 46.761537\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 47.682420\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000069 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 329\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 47.157592\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 330\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.369707\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000057 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 328\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.408590\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 46.981646\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 324\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 47.096547\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000194 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 329\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.121710\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000056 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 328\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 46.162202\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000265 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.559248\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000176 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 328\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 45.227351\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 48.032642\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000100 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 328\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 46.157715\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 328\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 47.978330\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000179 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 324\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 46.572944\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000070 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 329\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 45.361523\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000055 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 330\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 48.227327\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 329\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 47.626808\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 48.449794\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000165 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 329\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.751725\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000175 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 326\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 45.194808\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000167 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 329\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 48.519113\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 329\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 47.398053\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.621761\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 328\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 46.876469\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000058 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 328\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.620133\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000051 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 47.189606\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 332\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.624766\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000067 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 46.538400\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000095 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 46.144499\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000049 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 328\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 46.620638\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000171 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 47.639125\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000093 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 325\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 45.965726\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000048 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 322\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 47.515727\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000170 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 328\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 47.150817\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000052 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 328\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 46.633871\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000068 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 329\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 46.593551\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000054 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 328\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 45.312555\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000068 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 328\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 38\n",
            "[LightGBM] [Info] Start training from score 46.818842\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000111 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 37\n",
            "[LightGBM] [Info] Start training from score 47.058062\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000069 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 327\n",
            "[LightGBM] [Info] Number of data points in the train set: 928, number of used features: 39\n",
            "[LightGBM] [Info] Start training from score 47.289653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n",
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "훈련 세트 RMSE: 13.0799\n",
            "훈련 세트 R2: 0.6954\n",
            "테스트 세트 RMSE: 17.7533\n",
            "테스트 세트 R2: 0.3989\n"
          ]
        }
      ],
      "source": [
        "X = df.drop(columns=['popularity'])\n",
        "y = df['popularity']\n",
        "\n",
        "categorical_features = ['distributor', 'category', 'packaging', 'zero_type', 'sweetener_mix']\n",
        "numerical_features = ['ad_collab', 'price_100ml'] # volume 빠짐\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(), categorical_features)\n",
        "    ])\n",
        "\n",
        "# 2. LightGBM 모델을 Wrapping한 클래스를 base_estimator로 사용\n",
        "class LGBMWrapper(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, **params):\n",
        "        self.model = lgb.LGBMRegressor(**params)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "\n",
        "model = LGBMWrapper(num_leaves=31, max_depth=7, learning_rate=0.05)\n",
        "\n",
        "\n",
        "bagging_model = BaggingRegressor(estimator=model, n_estimators=50, random_state=42)\n",
        "\n",
        "\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('bagging', bagging_model)\n",
        "])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_pred_train = pipeline.predict(X_train)\n",
        "y_pred_test = pipeline.predict(X_test)\n",
        "\n",
        "rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "r2_train = r2_score(y_train, y_pred_train)\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "r2_test = r2_score(y_test, y_pred_test)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"훈련 세트 RMSE: {rmse_train:.4f}\")\n",
        "print(f\"훈련 세트 R2: {r2_train:.4f}\")\n",
        "print(f\"테스트 세트 RMSE: {rmse_test:.4f}\")\n",
        "print(f\"테스트 세트 R2: {r2_test:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70gfRSMMlRit",
        "outputId": "c8cdd90b-c708-4a1c-ea52-de4e8fd09647"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "모델 및 결과가 저장되었습니다.\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# 모델 파이프라인 저장\n",
        "joblib.dump(pipeline, 'beverage_model_pipeline.pkl')\n",
        "\n",
        "# 예측 결과 및 평가 지표 저장\n",
        "results = {\n",
        "    'Metric': ['RMSE (Train)', 'R2 (Train)', 'RMSE (Test)', 'R2 (Test)'],\n",
        "    'Value': [rmse_train, r2_train, rmse_test, r2_test]\n",
        "}\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_csv('model_evaluation_metrics.csv', index=False)\n",
        "\n",
        "# 예측 결과 저장\n",
        "predictions_df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred_test})\n",
        "predictions_df.to_csv('model_predictions.csv', index=False)\n",
        "\n",
        "print(\"모델 및 결과가 저장되었습니다.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVMnvlyWgK24"
      },
      "source": [
        "- 테스트 결과 'volume'변수 제외시 성능 향상을 보임.\n",
        "- 성능향상\n",
        "\n",
        "|| LightGBM 1st trial |LightGBM 모든변수 | LightGBM '용량' 제외 |\n",
        "|-|-|-|-|\n",
        "|RMSE|18.2220 |18.5474  | **17.7533** |\n",
        "|R2 Score| 0.3668 |0.3771 |  **0.3989** |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRh4ZmF1hXIl"
      },
      "source": [
        "- 모델 변수 : pipeline\n",
        "- 모델 설명력 : 약 40%\n",
        "- 평균 예측 오차: 17% (100%기준)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPMLo4u0iGUN"
      },
      "source": [
        "모델을 최대한 긍정적으로 설명하자면, 현재까지의 성과는 상당히 의미 있는 수준에 도달했다고 볼 수 있습니다.\n",
        "\n",
        "### 1. **모델 설명력 40%**:\n",
        "   - 모델의 **설명력**이 40%라는 것은, 데이터에서 **약 40%의 변동성**을 잘 설명할 수 있다는 것을 의미합니다. 이는 여전히 개선의 여지가 있지만, 여러 모델을 테스트한 결과에 비추어 보면 상당히 괜찮은 수준일 수 있습니다.\n",
        "   - 특히 복잡한 문제일수록, 설명력이 40%라는 것은 매우 잘한 결과일 수 있습니다. 예를 들어, **복잡한 패턴을 가진 데이터**에서는 40%의 설명력만으로도 **모델이 중요한 패턴을 포착**하고 있다는 신호일 수 있습니다.\n",
        "\n",
        "### 2. **평균 예측 오차 17% (100% 기준)**:\n",
        "   - **예측 오차가 17%**라는 것은 예측 값이 실제 값과 비교했을 때, **평균적으로 17%의 차이**를 보인다는 뜻입니다.\n",
        "   - 100% 기준으로 예측 오차가 17%라는 것은 **상당히 효율적**이라고 할 수 있습니다. 예측의 정확도는 이미 **상당히 높은 수준**에 있고, 데이터에 대한 예측력이 **실용적인 범위**에 도달했다고 볼 수 있습니다.\n",
        "   - 여러 방법을 테스트하여 **이 정도 성과**를 얻었다는 것은 모델이 상당히 **정교화되었고, 신뢰할 수 있는 예측 결과를 제공**하고 있다는 점에서 긍정적입니다.\n",
        "\n",
        "### 긍정적인 해석:\n",
        "- **모델 성능을 개선할 여지가 있다**는 점에서 **향후 추가 개선이 가능**하다는 것을 의미합니다. 예를 들어, 모델의 파라미터 조정이나, 특성 엔지니어링, 더 다양한 모델을 도입하는 방식으로 **설명력과 예측 정확도를 높여갈 수 있는 기회**가 존재합니다.\n",
        "- **현재의 결과가 실용적인 수준에 도달했다**는 점에서, 이를 실제 환경에 적용하기에 충분한 수준입니다. 예측 오차가 17%라면, **예측의 정확도**는 이미 **실용적인 범위**에 들어가고, 이 정도 정확도가 **비즈니스에서 유용한 결정 지원**을 할 수 있는 수준에 가까워졌습니다.\n",
        "\n",
        "따라서 현재 모델은 **긍정적인 결과를 도출해냈으며**, 추가적인 튜닝이나 개선을 통해 더 큰 성과를 이룰 가능성이 충분히 존재합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op91QwfRcSlx"
      },
      "source": [
        "#### 학습/훈련세트 분할 교차검증"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vze3OxDtaQk-",
        "outputId": "e143a166-8b37-4a4d-cb4d-83d753bb574d"
      },
      "outputs": [],
      "source": [
        "import lightgbm as lgb\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_validate, KFold\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "import numpy as np\n",
        "\n",
        "# 데이터 로드 및 전처리 (예시)\n",
        "# df는 주어진 데이터프레임을 가정합니다.\n",
        "\n",
        "# 1. 범주형 변수 One-Hot Encoding 및 연속형 변수 스케일링\n",
        "X = df.drop(columns=['popularity'])  # 'popularity'를 종속 변수로 설정\n",
        "y = df['popularity']  # 타겟 변수는 'popularity'\n",
        "\n",
        "# 범주형 변수 및 연속형 변수 목록\n",
        "categorical_features = ['distributor', 'category', 'packaging', 'zero_type', 'sweetener_mix']\n",
        "numerical_features = ['ad_collab', 'price_100ml']\n",
        "\n",
        "# 전처리 파이프라인 구성\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),  # 연속형 변수 정규화\n",
        "        ('cat', OneHotEncoder(), categorical_features)  # 범주형 변수 원-핫 인코딩\n",
        "    ])\n",
        "\n",
        "# 2. LightGBM 모델을 Wrapping한 클래스를 base_estimator로 사용\n",
        "class LGBMWrapper(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, **params):\n",
        "        self.model = lgb.LGBMRegressor(**params)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "# 3. BaggingRegressor에 LightGBM 모델을 사용\n",
        "model = LGBMWrapper(num_leaves=31, max_depth=7, learning_rate=0.05)\n",
        "\n",
        "# BaggingRegressor에 estimator로 사용\n",
        "bagging_model = BaggingRegressor(estimator=model, n_estimators=50, random_state=42)\n",
        "\n",
        "# 4. 파이프라인 구성\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('bagging', bagging_model)\n",
        "])\n",
        "\n",
        "# 5. 교차검증 설정: KFold 교차검증\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)  # 5-fold 교차검증\n",
        "\n",
        "# 6. 교차검증 수행\n",
        "cross_val_results = cross_validate(pipeline, X, y, cv=cv, scoring='neg_mean_squared_error', return_train_score=True)\n",
        "\n",
        "# 7. 각 폴드별 RMSE 계산 및 출력\n",
        "print(\"각 폴드별 RMSE:\")\n",
        "for fold_idx, test_score in enumerate(cross_val_results['test_score']):\n",
        "    print(test_score)\n",
        "    rmse = np.sqrt(-test_score)  # 부호 반전 후 제곱근 계산\n",
        "    print(f\"폴드 {fold_idx+1} - RMSE: {rmse:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRzb7hyahNO_"
      },
      "source": [
        "- 교차검증에서 의미있는 성능 향상을 보이진 않는다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2EmJ-0TjueN"
      },
      "source": [
        "# 새로운 데이터에 대한 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "kBuvhKBDjz7O",
        "outputId": "5cca3d01-d028-4fd3-f715-4524a2c12940"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>distributor</th>\n",
              "      <th>category</th>\n",
              "      <th>packaging</th>\n",
              "      <th>ad_collab</th>\n",
              "      <th>price_100ml</th>\n",
              "      <th>volume</th>\n",
              "      <th>zero_type</th>\n",
              "      <th>popularity</th>\n",
              "      <th>sweetener_mix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>페트</td>\n",
              "      <td>1</td>\n",
              "      <td>322</td>\n",
              "      <td>200</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>69.654006</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>페트</td>\n",
              "      <td>1</td>\n",
              "      <td>361</td>\n",
              "      <td>200</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>43.246780</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>유리병</td>\n",
              "      <td>0</td>\n",
              "      <td>528</td>\n",
              "      <td>150</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>73.306406</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>페트</td>\n",
              "      <td>0</td>\n",
              "      <td>273</td>\n",
              "      <td>500</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>40.011834</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>페트</td>\n",
              "      <td>0</td>\n",
              "      <td>296</td>\n",
              "      <td>500</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>58.161078</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  distributor category packaging  ad_collab  price_100ml  volume zero_type  \\\n",
              "0        광동제약        차        페트          1          322     200     일반 음료   \n",
              "1        광동제약        차        페트          1          361     200     일반 음료   \n",
              "2        광동제약        차       유리병          0          528     150     일반 음료   \n",
              "3        광동제약        차        페트          0          273     500     일반 음료   \n",
              "4        광동제약        차        페트          0          296     500     일반 음료   \n",
              "\n",
              "   popularity sweetener_mix  \n",
              "0   69.654006        대체당 없음  \n",
              "1   43.246780        대체당 없음  \n",
              "2   73.306406        대체당 없음  \n",
              "3   40.011834        대체당 없음  \n",
              "4   58.161078        대체당 없음  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BROzxKRKjzgW"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "qvS6CHDKlxvN",
        "outputId": "e82cac13-745f-4d34-9cd9-7dc619a2b3ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_15992\\3758250729.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_df.drop(columns=['popularity'], inplace=True)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>distributor</th>\n",
              "      <th>category</th>\n",
              "      <th>packaging</th>\n",
              "      <th>ad_collab</th>\n",
              "      <th>price_100ml</th>\n",
              "      <th>volume</th>\n",
              "      <th>zero_type</th>\n",
              "      <th>sweetener_mix</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>페트</td>\n",
              "      <td>1</td>\n",
              "      <td>322</td>\n",
              "      <td>200</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>페트</td>\n",
              "      <td>1</td>\n",
              "      <td>361</td>\n",
              "      <td>200</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>유리병</td>\n",
              "      <td>0</td>\n",
              "      <td>528</td>\n",
              "      <td>150</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>페트</td>\n",
              "      <td>0</td>\n",
              "      <td>273</td>\n",
              "      <td>500</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>페트</td>\n",
              "      <td>0</td>\n",
              "      <td>296</td>\n",
              "      <td>500</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>대체당 없음</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  distributor category packaging  ad_collab  price_100ml  volume zero_type  \\\n",
              "0        광동제약        차        페트          1          322     200     일반 음료   \n",
              "1        광동제약        차        페트          1          361     200     일반 음료   \n",
              "2        광동제약        차       유리병          0          528     150     일반 음료   \n",
              "3        광동제약        차        페트          0          273     500     일반 음료   \n",
              "4        광동제약        차        페트          0          296     500     일반 음료   \n",
              "\n",
              "  sweetener_mix  \n",
              "0        대체당 없음  \n",
              "1        대체당 없음  \n",
              "2        대체당 없음  \n",
              "3        대체당 없음  \n",
              "4        대체당 없음  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_df = df.head()\n",
        "new_df.drop(columns=['popularity'], inplace=True)\n",
        "new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'BaseEstimator' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mLGBMWrapper\u001b[39;00m(\u001b[43mBaseEstimator\u001b[49m, RegressorMixin):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[0;32m      3\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mLGBMRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'BaseEstimator' is not defined"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "trtfailVlWm5",
        "outputId": "7981b124-8510-4fe9-d97b-ce50dc33c9cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>distributor</th>\n",
              "      <th>category</th>\n",
              "      <th>packaging</th>\n",
              "      <th>ad_collab</th>\n",
              "      <th>price_100ml</th>\n",
              "      <th>volume</th>\n",
              "      <th>zero_type</th>\n",
              "      <th>sweetener_mix</th>\n",
              "      <th>popularity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>페트</td>\n",
              "      <td>1</td>\n",
              "      <td>322</td>\n",
              "      <td>200</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>대체당 없음</td>\n",
              "      <td>45.622759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>페트</td>\n",
              "      <td>1</td>\n",
              "      <td>361</td>\n",
              "      <td>200</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>대체당 없음</td>\n",
              "      <td>39.431742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>유리병</td>\n",
              "      <td>0</td>\n",
              "      <td>528</td>\n",
              "      <td>150</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>대체당 없음</td>\n",
              "      <td>57.974219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>페트</td>\n",
              "      <td>0</td>\n",
              "      <td>273</td>\n",
              "      <td>500</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>대체당 없음</td>\n",
              "      <td>46.095683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>광동제약</td>\n",
              "      <td>차</td>\n",
              "      <td>페트</td>\n",
              "      <td>0</td>\n",
              "      <td>296</td>\n",
              "      <td>500</td>\n",
              "      <td>일반 음료</td>\n",
              "      <td>대체당 없음</td>\n",
              "      <td>49.032151</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  distributor category packaging  ad_collab  price_100ml  volume zero_type  \\\n",
              "0        광동제약        차        페트          1          322     200     일반 음료   \n",
              "1        광동제약        차        페트          1          361     200     일반 음료   \n",
              "2        광동제약        차       유리병          0          528     150     일반 음료   \n",
              "3        광동제약        차        페트          0          273     500     일반 음료   \n",
              "4        광동제약        차        페트          0          296     500     일반 음료   \n",
              "\n",
              "  sweetener_mix  popularity  \n",
              "0        대체당 없음   45.622759  \n",
              "1        대체당 없음   39.431742  \n",
              "2        대체당 없음   57.974219  \n",
              "3        대체당 없음   46.095683  \n",
              "4        대체당 없음   49.032151  "
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "\n",
        "class LGBMWrapper(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, **params):\n",
        "        self.model = lgb.LGBMRegressor(**params)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "\n",
        "# 저장된 모델 로드\n",
        "pipeline = joblib.load('beverage_model_pipeline.pkl')\n",
        "\n",
        "\n",
        "''' 새로운 데이터 : new_df'''\n",
        "\n",
        "# 모델에 맞게 입력 데이터 가져오기\n",
        "X_new = new_df[['distributor', 'category', 'packaging', 'zero_type', 'sweetener_mix', 'ad_collab', 'price_100ml']]\n",
        "\n",
        "\n",
        "# 새로운 데이터 예측\n",
        "y_new_pred = pipeline.predict(X_new)\n",
        "y_new_pred\n",
        "new_df['popularity'] = y_new_pred\n",
        "new_df\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
